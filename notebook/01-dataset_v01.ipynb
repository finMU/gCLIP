{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLIP - Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset - Line by Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 image - transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(img_size: int, max_pixel_value: float = 255.0, stage: str = \"train\"):\n",
    "    if stage == \"train\":\n",
    "        transform = A.Compose(\n",
    "            [\n",
    "                A.Resize(img_size, img_size, always_apply=True),\n",
    "                A.Normalize(max_pixel_value=max_pixel_value, always_apply=True),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        transform = A.Compose(\n",
    "            [\n",
    "                A.Resize(img_size, img_size, always_apply=True),\n",
    "                A.Normalize(max_pixel_value=max_pixel_value, always_apply=True),\n",
    "                ToTensorV2(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transform(img_size=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 text - tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"../data/images\"\n",
    "caption_path = \"../data/captions.csv\"\n",
    "info_df = pd.read_csv(caption_path, encoding_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df[\"image_path\"] = info_df[\"image_name\"].apply(\n",
    "    lambda row: f\"{row.split('_')[0]}/{row}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>caption</th>\n",
       "      <th>label_game</th>\n",
       "      <th>label_genre</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bingsu_img_0.png</td>\n",
       "      <td>The image shows a lobby from the popular multi...</td>\n",
       "      <td>among_us</td>\n",
       "      <td>strategy</td>\n",
       "      <td>bingsu/bingsu_img_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bingsu_img_0.png</td>\n",
       "      <td>The lobby in \"Among Us\" is depicted in the ima...</td>\n",
       "      <td>among_us</td>\n",
       "      <td>strategy</td>\n",
       "      <td>bingsu/bingsu_img_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bingsu_img_0.png</td>\n",
       "      <td>The lobby in the image is from the well-known ...</td>\n",
       "      <td>among_us</td>\n",
       "      <td>strategy</td>\n",
       "      <td>bingsu/bingsu_img_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bingsu_img_0.png</td>\n",
       "      <td>The picture displays a waiting area in the wel...</td>\n",
       "      <td>among_us</td>\n",
       "      <td>strategy</td>\n",
       "      <td>bingsu/bingsu_img_0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bingsu_img_0.png</td>\n",
       "      <td>The picture displays a lobby in the well-liked...</td>\n",
       "      <td>among_us</td>\n",
       "      <td>strategy</td>\n",
       "      <td>bingsu/bingsu_img_0.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name                                            caption  \\\n",
       "0  bingsu_img_0.png  The image shows a lobby from the popular multi...   \n",
       "1  bingsu_img_0.png  The lobby in \"Among Us\" is depicted in the ima...   \n",
       "2  bingsu_img_0.png  The lobby in the image is from the well-known ...   \n",
       "3  bingsu_img_0.png  The picture displays a waiting area in the wel...   \n",
       "4  bingsu_img_0.png  The picture displays a lobby in the well-liked...   \n",
       "\n",
       "  label_game label_genre               image_path  \n",
       "0   among_us    strategy  bingsu/bingsu_img_0.png  \n",
       "1   among_us    strategy  bingsu/bingsu_img_0.png  \n",
       "2   among_us    strategy  bingsu/bingsu_img_0.png  \n",
       "3   among_us    strategy  bingsu/bingsu_img_0.png  \n",
       "4   among_us    strategy  bingsu/bingsu_img_0.png  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 img & text -  preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.choice(range(len(info_df)))\n",
    "\n",
    "image_name = info_df.iloc[idx][\"image_name\"]\n",
    "caption = info_df.iloc[idx][\"caption\"]\n",
    "game_name = info_df.iloc[idx][\"label_game\"]\n",
    "game_genre = info_df.iloc[idx][\"label_genre\"]\n",
    "image_path = info_df.iloc[idx][\"image_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "\n",
    "captions = info_df[\"caption\"].tolist()\n",
    "encoded_captions = tokenizer(\n",
    "    captions, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([43392, 145])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_captions[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.path.join(img_dir, image_path)\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img = transform(image=img)[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = {k: v[idx] for k, v in encoded_captions.items()}\n",
    "item[\"image\"] = img\n",
    "item[\"caption\"] = caption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset - Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        img_dir: str,\n",
    "        tokenizer,\n",
    "        transform,\n",
    "        txt_max_length: int = 200,\n",
    "    ):\n",
    "        self.img_dir = img_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.txt_max_length = txt_max_length\n",
    "\n",
    "        # dataframe\n",
    "        self.data = df\n",
    "        self.data[\"image_path\"] = self.data[\"image_name\"].apply(\n",
    "            lambda row: f\"{row.split('_')[0]}/{row}\"\n",
    "        )\n",
    "\n",
    "        # encoded_captions\n",
    "        captions = self.data[\"caption\"].tolist()\n",
    "        self.encoded_captions = self.tokenizer(\n",
    "            captions,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=self.txt_max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.data.iloc[idx][\"image_name\"]\n",
    "        caption = self.data.iloc[idx][\"caption\"]\n",
    "        game_name = self.data.iloc[idx][\"label_game\"]\n",
    "        game_genre = self.data.iloc[idx][\"label_genre\"]\n",
    "        image_path = self.data.iloc[idx][\"image_path\"]\n",
    "\n",
    "        # txt prep\n",
    "        item = {k: v[idx] for k, v in self.encoded_captions.items()}\n",
    "\n",
    "        # img prep\n",
    "        img_path = os.path.join(self.img_dir, image_path)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(image=img)[\"image\"]\n",
    "\n",
    "        item[\"image\"] = img\n",
    "        item[\"caption\"] = caption\n",
    "        item[\"game_name\"] = game_name\n",
    "        item[\"game_genre\"] = game_genre\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/captions.csv\"\n",
    "img_dir = \"../data/images/\"\n",
    "tokenizer_name = \"bert-base-uncased\"\n",
    "img_size = 224\n",
    "txt_max_length = 200\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "transform = get_transform(img_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "val_size = 0.2\n",
    "\n",
    "df = pd.read_csv(data_path, encoding_errors=\"ignore\")\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=test_size, shuffle=True)\n",
    "train_df, val_df = train_test_split(train_df, test_size=test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CLIPDataset(train_df, img_dir, tokenizer, transform, txt_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1999, 2023,  ...,    0,    0,    0],\n",
       "         [ 101, 1999, 1996,  ...,    0,    0,    0],\n",
       "         [ 101, 1996, 3746,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 1999, 1996,  ...,    0,    0,    0],\n",
       "         [ 101, 1037, 2447,  ...,    0,    0,    0],\n",
       "         [ 101, 1999, 1996,  ...,    0,    0,    0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'image': tensor([[[[-0.5767, -0.5767, -0.5767,  ..., -1.3644, -1.3644, -1.3644],\n",
       "           [-0.5596, -0.5596, -0.5596,  ..., -1.3644, -1.3644, -1.3644],\n",
       "           [-0.5596, -0.5596, -0.5596,  ..., -1.3473, -1.3473, -1.3473],\n",
       "           ...,\n",
       "           [-1.4843, -1.4843, -1.4843,  ..., -1.1760, -1.1760, -1.1760],\n",
       "           [-1.4843, -1.4843, -1.4843,  ..., -1.1760, -1.1760, -1.1760],\n",
       "           [-1.4843, -1.4843, -1.4843,  ..., -1.1760, -1.1760, -1.1760]],\n",
       " \n",
       "          [[-0.6176, -0.6176, -0.6352,  ..., -0.3901, -0.3901, -0.3901],\n",
       "           [-0.6352, -0.6352, -0.6527,  ..., -0.3901, -0.3901, -0.3901],\n",
       "           [-0.6352, -0.6352, -0.6527,  ..., -0.3725, -0.3725, -0.3725],\n",
       "           ...,\n",
       "           [-1.3179, -1.3179, -1.3179,  ..., -1.0553, -1.0553, -1.0553],\n",
       "           [-1.3179, -1.3179, -1.3179,  ..., -1.0553, -1.0553, -1.0553],\n",
       "           [-1.3179, -1.3179, -1.3179,  ..., -1.0553, -1.0553, -1.0553]],\n",
       " \n",
       "          [[-1.7173, -1.7173, -1.6999,  ...,  0.7751,  0.7751,  0.7751],\n",
       "           [-1.6824, -1.6824, -1.6999,  ...,  0.7751,  0.7751,  0.7751],\n",
       "           [-1.6824, -1.6824, -1.6824,  ...,  0.7925,  0.7925,  0.7925],\n",
       "           ...,\n",
       "           [-1.0550, -1.0376, -1.0201,  ..., -0.7761, -0.7761, -0.7761],\n",
       "           [-1.0550, -1.0376, -1.0201,  ..., -0.7761, -0.7761, -0.7761],\n",
       "           [-1.0550, -1.0201, -1.0201,  ..., -0.7761, -0.7761, -0.7761]]],\n",
       " \n",
       " \n",
       "         [[[-1.1247, -1.1418, -1.1247,  ..., -0.9363, -0.9705, -0.9877],\n",
       "           [-1.0562, -1.0562, -1.0562,  ..., -0.8678, -0.9192, -0.9877],\n",
       "           [-1.0219, -1.0219, -0.9877,  ..., -1.0904, -1.0562, -1.0048],\n",
       "           ...,\n",
       "           [ 0.6906,  0.7248,  0.6049,  ..., -0.9363, -0.9534, -0.9363],\n",
       "           [ 0.7248,  0.6392,  0.5707,  ..., -0.9363, -0.9534, -0.9363],\n",
       "           [ 0.6563,  0.5536,  0.5193,  ..., -0.9363, -0.9705, -0.9705]],\n",
       " \n",
       "          [[-1.4405, -1.4580, -1.4405,  ..., -1.1604, -1.1954, -1.2129],\n",
       "           [-1.3704, -1.3704, -1.3704,  ..., -1.1078, -1.1604, -1.2129],\n",
       "           [-1.3354, -1.3354, -1.3004,  ..., -1.2654, -1.2479, -1.2129],\n",
       "           ...,\n",
       "           [ 0.4328,  0.4503,  0.3627,  ..., -1.1253, -1.1078, -1.0903],\n",
       "           [ 0.5203,  0.3803,  0.3277,  ..., -1.1078, -1.1078, -1.0903],\n",
       "           [ 0.5378,  0.3803,  0.3452,  ..., -1.0903, -1.0728, -1.0728]],\n",
       " \n",
       "          [[-1.3164, -1.3339, -1.3164,  ..., -0.9678, -1.0027, -1.0201],\n",
       "           [-1.2467, -1.2467, -1.2467,  ..., -0.8981, -0.9504, -1.0201],\n",
       "           [-1.2119, -1.2119, -1.1770,  ..., -1.0201, -1.0027, -0.9504],\n",
       "           ...,\n",
       "           [ 0.4439,  0.4962,  0.4439,  ..., -0.7238, -0.7064, -0.6890],\n",
       "           [ 0.5485,  0.4614,  0.4091,  ..., -0.6890, -0.6890, -0.6715],\n",
       "           [ 0.5834,  0.4788,  0.4439,  ..., -0.6715, -0.6715, -0.6715]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2385,  1.1529,  0.7419,  ...,  0.6392,  0.6392,  0.7933],\n",
       "           [ 1.2385,  1.1529,  0.7419,  ...,  0.1939,  0.5022,  0.7933],\n",
       "           [ 1.2557,  1.2043,  0.9474,  ...,  1.3584,  0.8447,  0.7933],\n",
       "           ...,\n",
       "           [ 1.2557,  1.5125,  0.7419,  ...,  1.2728,  1.2899,  1.2899],\n",
       "           [ 1.2214,  1.2043,  1.5639,  ...,  1.1700,  1.1700,  1.2043],\n",
       "           [ 1.0331,  1.3070,  1.4783,  ...,  1.2043,  1.1700,  1.2043]],\n",
       " \n",
       "          [[ 0.9230,  1.0630,  1.0105,  ...,  1.2556,  1.2381,  1.3431],\n",
       "           [ 0.9230,  1.0630,  1.0105,  ...,  0.7304,  1.0805,  1.3431],\n",
       "           [ 0.8880,  1.0980,  1.1681,  ...,  1.6408,  1.2731,  1.3431],\n",
       "           ...,\n",
       "           [ 1.2556,  1.4307,  0.4853,  ...,  1.3256,  1.3431,  1.3606],\n",
       "           [ 1.2731,  1.1155,  1.6583,  ...,  1.2031,  1.2031,  1.2381],\n",
       "           [ 1.0980,  1.2381,  1.1856,  ...,  1.2381,  1.2031,  1.2381]],\n",
       " \n",
       "          [[ 0.3219,  0.3916,  0.1999,  ...,  0.7054,  0.4962,  0.5136],\n",
       "           [ 0.3219,  0.3916,  0.1999,  ...,  0.2173,  0.3742,  0.5136],\n",
       "           [ 0.3393,  0.4614,  0.4091,  ...,  1.4897,  0.7402,  0.5136],\n",
       "           ...,\n",
       "           [ 1.3677,  1.2805, -0.3230,  ...,  1.4722,  1.4897,  1.5245],\n",
       "           [ 1.4025,  0.8448, -0.6367,  ...,  1.3851,  1.3851,  1.4200],\n",
       "           [ 1.1934,  0.8274,  0.3916,  ...,  1.4200,  1.3851,  1.4200]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.5596, -0.5596, -0.5596,  ..., -0.4739, -0.5253, -0.5424],\n",
       "           [-0.5596, -0.5596, -0.5596,  ..., -0.4739, -0.5253, -0.5424],\n",
       "           [-0.5596, -0.5596, -0.5424,  ..., -0.4739, -0.5082, -0.5253],\n",
       "           ...,\n",
       "           [-1.2788, -1.2617, -1.2788,  ..., -1.3644, -1.2959, -1.3302],\n",
       "           [-1.3130, -1.3644, -1.3987,  ..., -1.3644, -1.2959, -1.3302],\n",
       "           [-1.2959, -1.2788, -1.4500,  ..., -1.3644, -1.2617, -1.3473]],\n",
       " \n",
       "          [[-0.5301, -0.5301, -0.5301,  ..., -0.4426, -0.4951, -0.5126],\n",
       "           [-0.5301, -0.5301, -0.5301,  ..., -0.4426, -0.4951, -0.5126],\n",
       "           [-0.5301, -0.5301, -0.5301,  ..., -0.4251, -0.4776, -0.4951],\n",
       "           ...,\n",
       "           [-1.2829, -1.3179, -1.3354,  ..., -1.3704, -1.3004, -1.3354],\n",
       "           [-1.3179, -1.4230, -1.4580,  ..., -1.3704, -1.3004, -1.3354],\n",
       "           [-1.3004, -1.3354, -1.5105,  ..., -1.3704, -1.2654, -1.3529]],\n",
       " \n",
       "          [[-0.3578, -0.3578, -0.3578,  ..., -0.3055, -0.3578, -0.3753],\n",
       "           [-0.3578, -0.3578, -0.3578,  ..., -0.3055, -0.3578, -0.3753],\n",
       "           [-0.3578, -0.3578, -0.3578,  ..., -0.3055, -0.3404, -0.3578],\n",
       "           ...,\n",
       "           [-1.3339, -1.4036, -1.3687,  ..., -1.3339, -1.2641, -1.2990],\n",
       "           [-1.3687, -1.5081, -1.5081,  ..., -1.3164, -1.2467, -1.2816],\n",
       "           [-1.3513, -1.4210, -1.5430,  ..., -1.3164, -1.2119, -1.2990]]],\n",
       " \n",
       " \n",
       "         [[[-0.0287, -0.2171, -0.4054,  ..., -1.6042, -1.3473, -1.0048],\n",
       "           [-1.5014,  0.3309, -0.2171,  ..., -1.5870, -1.1760, -1.1418],\n",
       "           [-1.5014, -1.0904,  0.3823,  ...,  1.2557, -0.6452, -1.2274],\n",
       "           ...,\n",
       "           [-1.2959, -0.9534,  0.6049,  ..., -1.0219, -0.8335, -0.8507],\n",
       "           [-1.2445, -1.2617,  1.3584,  ..., -0.9192, -0.8164, -0.8849],\n",
       "           [-1.1932, -1.2788, -0.5596,  ..., -0.7479, -0.8164, -0.9020]],\n",
       " \n",
       "          [[ 0.4153,  0.4153,  0.4853,  ..., -1.0903, -0.8452, -0.6527],\n",
       "           [-1.1078,  0.9055,  0.5553,  ..., -1.0903, -0.7052, -0.8277],\n",
       "           [-1.0203, -0.6176,  1.0630,  ...,  1.5182, -0.2850, -0.9153],\n",
       "           ...,\n",
       "           [-0.3550, -0.3725,  0.3452,  ..., -0.3725, -0.1450, -0.1975],\n",
       "           [-0.3200, -0.4601,  1.5882,  ..., -0.2325, -0.0224, -0.0574],\n",
       "           [-0.2675, -0.3725,  0.2052,  ..., -0.0574, -0.0049, -0.0574]],\n",
       " \n",
       "          [[ 0.0953, -0.3230, -0.7587,  ..., -1.5604, -1.4907, -1.5779],\n",
       "           [-1.3861,  0.3568, -0.4275,  ..., -1.4733, -1.3164, -1.7347],\n",
       "           [-1.5256, -0.9678,  0.4439,  ...,  1.6117, -0.7064, -1.8044],\n",
       "           ...,\n",
       "           [-1.5779, -1.6127, -0.1661,  ..., -1.3164, -1.1944, -1.1944],\n",
       "           [-1.5256, -1.6302, -1.0376,  ..., -1.2467, -1.2816, -1.3861],\n",
       "           [-1.4733, -1.6302, -1.2641,  ..., -1.1247, -1.2641, -1.4559]]],\n",
       " \n",
       " \n",
       "         [[[-1.5699, -1.5699, -1.5699,  ..., -1.6727, -1.6727, -1.6727],\n",
       "           [-1.5699, -1.5699, -1.5699,  ..., -1.6727, -1.6727, -1.6727],\n",
       "           [-1.5699, -1.5699, -1.5699,  ..., -1.6727, -1.6727, -1.6727],\n",
       "           ...,\n",
       "           [-1.9124, -1.9124, -1.8782,  ..., -1.6727, -1.6555, -1.6213],\n",
       "           [-1.9124, -1.9124, -1.8953,  ..., -1.6384, -1.6384, -1.6384],\n",
       "           [-1.9124, -1.9124, -1.8953,  ..., -1.7069, -1.7069, -1.6555]],\n",
       " \n",
       "          [[-1.5280, -1.5280, -1.5280,  ..., -1.6331, -1.6331, -1.6331],\n",
       "           [-1.5280, -1.5280, -1.5280,  ..., -1.6331, -1.6331, -1.6331],\n",
       "           [-1.5280, -1.5280, -1.5280,  ..., -1.6331, -1.6331, -1.6331],\n",
       "           ...,\n",
       "           [-1.7556, -1.7556, -1.7731,  ..., -1.6331, -1.6331, -1.6331],\n",
       "           [-1.7556, -1.7556, -1.7731,  ..., -1.5805, -1.5805, -1.6331],\n",
       "           [-1.7556, -1.7556, -1.7731,  ..., -1.6506, -1.6506, -1.6506]],\n",
       " \n",
       "          [[-1.2293, -1.2293, -1.2293,  ..., -1.3339, -1.3339, -1.3339],\n",
       "           [-1.2293, -1.2293, -1.2293,  ..., -1.3339, -1.3339, -1.3339],\n",
       "           [-1.2293, -1.2293, -1.2293,  ..., -1.3339, -1.3339, -1.3339],\n",
       "           ...,\n",
       "           [-1.3861, -1.3861, -1.3861,  ..., -1.3513, -1.3513, -1.3687],\n",
       "           [-1.3861, -1.3861, -1.3861,  ..., -1.3339, -1.3339, -1.3687],\n",
       "           [-1.3861, -1.3861, -1.3861,  ..., -1.4036, -1.3861, -1.3861]]]]),\n",
       " 'caption': [\"The player in the picture is engaged in a first-person shooter game, possibly navigating through a grassy area with modern buildings. The heads-up display (HUD) shows the player's health, shields, and weapon status, as well as the team's condition and the progress of the game, including the number of remaining squads and players. The minimap in the top left corner displays the player's location within the game and the next safe zone, while all three indicators for the player's squad are green, indicating that they are still together.\",\n",
       "  \"A character in a video game is shown participating in a battle with an enemy in a vibrant and leafy surroundings. The character appears to have successfully attacked the enemy, as indicated by the explosion of red particles and the enemy's unsteady stance.\",\n",
       "  'The player is seen in this picture positioned inside a wooden construction, featuring an open doorway that leads to a well-lit outdoor area containing different objects and another structure visible in the far distance. The player is carrying firearms and seems prepared for battle, as evidenced by the fully filled health and shield bars displayed at the bottom of the display.',\n",
       "  'The picture displays the lobby screen of the widely played game \"Among Us,\" located on The Skeld map. A complete game is shown with 10 players in the lobby, and on the left side, different game settings are visible. One player is currently personalizing their character\\'s look by selecting options for color, hat, pet, and skin.',\n",
       "  'In the photo, there is a scene featuring a character from the game \"Genshin Impact\" inside a room with a comfortable and inviting lighting atmosphere. They are joined by a small, ethereal creature resembling a fairy. It seems that they are taking a break or engaged in a conversation, while the background is adorned with various maps and objects, indicating a setting suited for planning or strategizing.',\n",
       "  'The picture shows a player in a dimly lit room, pointing a gun towards a window. Through the window, another character can be seen hanging upside down in a different area. The lighting hints at a sneaky or intense situation, which is often found in tactical shooter games where successfully ambushing or silently maneuvering through environments is crucial.',\n",
       "  'The player in the picture is participating in a build battle in Fortnite, constructing ramps and walls for defense and strategic advantage. They have different materials and weapons, suggesting that it is a later stage in the game where they are trying to outplay opponents and secure a better position in the shrinking safe zone.',\n",
       "  'In the picture, a person is engaging in a game session of a futuristic first-person shooter. They have a compound bow and the display shows that there are still 5 squads left and 12 players alive, while the 4th round of the game is about to end in six minutes.',\n",
       "  'The picture displays a task screen from the game \"Among Us\" where the player is currently located in the Upper Engine room and has the job of aligning the engine output. The interface implies that this is only one of many tasks the player must finish, and there is a visual prompt on the screen for aligning the engine, which remains undone.',\n",
       "  'The player in the picture is participating in a game called \"Among Us\" and is positioned in the middle of the map near regions called \\'Storage\\', \\'Communications\\', and \\'Shields\\'. The user interface elements on the screen confirm that the player is an Impostor because they have the choice to \"Sabotage\" or \"Kill\" and also have \"Fake Tasks\" to appear like a Crewmate.',\n",
       "  'The picture shows Jean introducing herself and giving the impression that she is about to introduce Lisa. This scene is set in a cozy indoor environment, possibly in an RPG game where characters are having a conversation.',\n",
       "  'The Dressing Room interface in the image showcases a character from \"Genshin Impact\" where players have the option to customize appearances, including wind gliders like the \"Wings of Descension,\" allowing them to equip their character with this stylish wind glider and explore the game\\'s expansive open world.',\n",
       "  'The player in the picture is participating in a first-person shooter game, possibly a battle royale, as indicated by the terms \"squads\" and \"47\" indicating the number of players or teams left. The message on the screen, \"SONAR DETECTED,\" implies that the player\\'s location has been disclosed to enemies, increasing the intensity of the gameplay.',\n",
       "  \"A diverse group of characters is seen in the image, standing around and constructing buildings in the background, indicating that a player is taking part in Fortnite's pre-game lobby. The player is holding a pickaxe, a fundamental tool used in the game for collecting materials, and appears to be gazing at the virtual landscape, possibly anticipating the beginning of the match.\",\n",
       "  \"The picture depicts a screen capture from the video game Genshin Impact, featuring a notification that rewards players with 50000 Mora, the game's currency, for completing a preferences survey. The visual components around the notification indicate that this scene occurs within the game's interface, potentially during a loading screen or transition.\",\n",
       "  \"The picture shows a video game character wearing armor that looks like it's from the medieval era. They are exploring a dimly-lit interior that could be a dungeon or cave. The environment is filled with wooden structures, barrels, and candlelight, giving off a sense of exploration and possible danger.\",\n",
       "  \"The displayed image in the game seems to be a screenshot from a battle royale game, possibly Fortnite, revealing a vibrant map with different named areas. On the map, there is a circle that gradually gets smaller, which players have to approach to prevent getting hurt. The interface also shows the player's inventory and a timer counting down, indicating that there are 2 minutes and 30 seconds left until the storm circle shrinks.\",\n",
       "  \"The player is situated in a grassy outdoor setting with futuristic elements, holding a bow and directing it towards a target, as depicted in the image. The heads-up display (HUD) reveals that the player's team consists of three members, while a countdown timer of 9 seconds indicates the approaching end of the game area or an upcoming event within the game.\",\n",
       "  'In the image, the player is at a level-up screen in a video game, possibly from the \"Dark Souls\" series or a similar role-playing game, indicating that they can allocate attribute points to improve their character\\'s abilities. The current character attributes such as Vigor, Mind, Endurance, Strength, and others are displayed, with an option to confirm any changes made to the distribution of points.',\n",
       "  'In the picture, there is a vibrant, medieval-inspired village with a character named Amber from the video game \"Genshin Impact\" featured prominently. She can be seen in the foreground with a dialogue bubble displaying confidence towards another character named Jean. Additionally, there is another character going about their activities in the background.',\n",
       "  'In the image, a player character is cautiously approaching an area where a large, armed enemy creature is waiting, indicating a likely combat situation in a dark fantasy game setting. The user interface elements on the screen, such as health bars, stamina, and item shortcuts, suggest this is a moment of tension before the player engages in battle.',\n",
       "  'The image showcases a menu in the video game \"Apex Legends\" that presents a friends list with online players. The status \"Playing\" indicates that certain players are currently participating in a match, while others are situated in the lobby with statuses like \"In Lobby.\" To maintain privacy, a few player names have been concealed or edited.',\n",
       "  'The screen that appears in the image shows a \"Match Summary\" page of a video game, which reveals that the player\\'s team came in 19th place in a match. The image is only partially obscured, and various user interface components indicate that it is from a game that involves playing as part of a team, potentially a battle royale game.',\n",
       "  \"During the voting session in the game Among Us, players are engaged in a conversation, trying to determine the imposter's identity by sharing their suspicions using the game's chat function. The image showcases players expressing their thoughts, with one player offering an apology and another player challenging someone else's suspicion, emphasizing the game's social manipulation element.\",\n",
       "  \"The picture shows a character navigating a dim cavern filled with ambient light sources. The top of the screen displays the character's orientation (facing east) and provides information on their combat abilities, like health, stamina, and equipped items, indicating that the player is exploring and ready for possible battles.\",\n",
       "  \"The player is playing Fortnite in the picture, standing on what looks like a metal structure, with a colorful landscape from the game in the background. The player's inventory at the bottom of the screen shows that they have a pickaxe equipped and their health and shield levels are both full, as indicated by the indicators at the bottom left.\",\n",
       "  'In the image, there is a character from the game \\'Fortnite\\' displayed on the screen, dressed in a pink and black outfit, standing in a readiness pose. The user interface shows that the game is on the \"Social\" tab, indicating that the player might be looking to manage their friends list or join others in the game.',\n",
       "  \"The picture shows a gamer participating in a battle royale-style game, possibly Fortnite, with a glider in the sky above a large and vibrant game world. The player's health and shield levels are displayed as full on the heads-up display (HUD), and there is also a map in the top right corner. Additionally, there is a notification about a storm forming, which is a game feature that forces players to converge as the game continues.\",\n",
       "  'The player of the game \"Genshin Impact\" has recently acquired a \"Silver Sword\" item, as shown by the notification on the screen, while a character from the game stands in a beautiful, expansive setting with greenery, a bridge, and mountains in the background.',\n",
       "  'In the picture, a third-person point of view shows a player character navigating a desolate, marshy setting with lifeless trees and fog. Close by, three humanoid beings can be observed, with two of them hunched down, suggesting a possible stealth mission or encounter in the game.',\n",
       "  'In the image, a player is parachuting into a gaming environment, specifically above an urban area marked as \"Lazy Lake\" in the game, which appears to be a part of the online multiplayer game Fortnite. The player is likely at the start of a match, preparing to land and begin scavenging for items and engaging with other players in combat.',\n",
       "  'The picture displays a video game scene where a character on a horse is carefully maneuvering through a desolate and rugged environment, possibly near a cliff or steep slope. The absence of any visible danger indicated by the health bar implies that the character could be in a peaceful situation, yet still remaining cautious due to possible environmental dangers.'],\n",
       " 'game_name': ['apex_legends',\n",
       "  'genshin_impact',\n",
       "  'fortnite',\n",
       "  'among_us',\n",
       "  'genshin_impact',\n",
       "  'call_of_duty',\n",
       "  'fortnite',\n",
       "  'apex_legends',\n",
       "  'among_us',\n",
       "  'among_us',\n",
       "  'genshin_impact',\n",
       "  'genshin_impact',\n",
       "  'apex_legends',\n",
       "  'fortnite',\n",
       "  'genshin_impact',\n",
       "  'elden_ring',\n",
       "  'fortnite',\n",
       "  'apex_legends',\n",
       "  'elden_ring',\n",
       "  'genshin_impact',\n",
       "  'elden_ring',\n",
       "  'apex_legends',\n",
       "  'apex_legends',\n",
       "  'among_us',\n",
       "  'elden_ring',\n",
       "  'fortnite',\n",
       "  'fortnite',\n",
       "  'fortnite',\n",
       "  'genshin_impact',\n",
       "  'elden_ring',\n",
       "  'fortnite',\n",
       "  'elden_ring'],\n",
       " 'game_genre': ['battle_royale',\n",
       "  'role_playing',\n",
       "  'battle_royale',\n",
       "  'strategy',\n",
       "  'role_playing',\n",
       "  'shooter',\n",
       "  'battle_royale',\n",
       "  'battle_royale',\n",
       "  'strategy',\n",
       "  'strategy',\n",
       "  'role_playing',\n",
       "  'role_playing',\n",
       "  'battle_royale',\n",
       "  'battle_royale',\n",
       "  'role_playing',\n",
       "  'role_playing',\n",
       "  'battle_royale',\n",
       "  'battle_royale',\n",
       "  'role_playing',\n",
       "  'role_playing',\n",
       "  'role_playing',\n",
       "  'battle_royale',\n",
       "  'battle_royale',\n",
       "  'strategy',\n",
       "  'role_playing',\n",
       "  'battle_royale',\n",
       "  'battle_royale',\n",
       "  'battle_royale',\n",
       "  'role_playing',\n",
       "  'role_playing',\n",
       "  'battle_royale',\n",
       "  'role_playing']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPDataModule:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        img_dir: str,\n",
    "        tokenizer_name: str,\n",
    "        img_size: int = 224,\n",
    "        txt_max_length: int = 200,\n",
    "        val_size: float = 0.2,\n",
    "        test_size: float = 0.2,\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 4,\n",
    "    ):\n",
    "        self.data_path = data_path\n",
    "        self.img_dir = img_dir\n",
    "        self.tokenizer_name = tokenizer_name\n",
    "        self.img_size = img_size\n",
    "        self.txt_max_length = txt_max_length\n",
    "        self.val_size = val_size\n",
    "        self.test_size = test_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def setup(self):\n",
    "        # load data\n",
    "        self.df = pd.read_csv(self.data_path, encoding_errors=\"ignore\")\n",
    "        self.df[\"image_path\"] = self.df[\"image_name\"].apply(\n",
    "            lambda row: f\"{row.split('_')[0]}/{row}\"\n",
    "        )\n",
    "\n",
    "        # tokenizer & transform\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.tokenizer_name)\n",
    "        self.train_transform = get_transform(img_size=self.img_size, stage=\"train\")\n",
    "        self.test_transform = get_transform(img_size=self.img_size, stage=\"test\")\n",
    "\n",
    "        # train/val/test split\n",
    "        train_df, test_df = train_test_split(\n",
    "            self.df, test_size=self.test_size, shuffle=True\n",
    "        )\n",
    "        train_df, val_df = train_test_split(\n",
    "            train_df, test_size=self.test_size, shuffle=True\n",
    "        )\n",
    "\n",
    "        # train/val/test set\n",
    "        self.trainset = CLIPDataset(\n",
    "            train_df,\n",
    "            self.img_dir,\n",
    "            self.tokenizer,\n",
    "            self.train_transform,\n",
    "            self.txt_max_length,\n",
    "        )\n",
    "        self.valset = CLIPDataset(\n",
    "            val_df,\n",
    "            self.img_dir,\n",
    "            self.tokenizer,\n",
    "            self.test_transform,\n",
    "            self.txt_max_length,\n",
    "        )\n",
    "        self.testset = CLIPDataset(\n",
    "            test_df,\n",
    "            self.img_dir,\n",
    "            self.tokenizer,\n",
    "            self.test_transform,\n",
    "            self.txt_max_length,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.trainset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.testset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_params = {\n",
    "    \"data_path\": \"../data/captions.csv\",\n",
    "    \"img_dir\": \"../data/images/\",\n",
    "    \"tokenizer_name\": \"bert-base-uncased\",\n",
    "    \"img_size\": 224,\n",
    "    \"txt_max_length\": 200,\n",
    "    \"val_size\": 0.2,\n",
    "    \"test_size\": 0.2,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "\n",
    "dm = CLIPDataModule(**dm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = next(iter(dm.train_dataloader()))\n",
    "val_batch = next(iter(dm.val_dataloader()))\n",
    "test_batch = next(iter(dm.test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'image', 'caption', 'game_name', 'game_genre'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 ('gclip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15b6d287f2a01b064242a5db7155158bf7f3638b6b99c51e9d30d6c2bf5cc073"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
